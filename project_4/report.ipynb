{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "38676564",
   "metadata": {},
   "source": [
    "# BigData 2025: Project 4\n",
    "Students: Kalju Jake Nekvasil, Joosep Orasm√§e, Tanel Tiisler, Kaupo Humal"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3025a497",
   "metadata": {},
   "source": [
    "## Data Ingestion and Preparation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "59f83910-9da7-4430-9587-165824298a76",
   "metadata": {},
   "source": [
    "We are using 2009 US domestic airline data in CSV format. The dataset is cleaned and saved. Different ML models are tried to predict cancellation with both accuracy and AOC scores. Best model was used to predict 2010 data too."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ed6f535b",
   "metadata": {},
   "source": [
    "## Cleaning and Preprocessing"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7945b711-ff6b-465b-91d9-642ba58b478e",
   "metadata": {},
   "source": [
    "Columns were renamed for readability and unnamed columns were dropped. Checked that categorical values are not empty and 0 was put as most likely value for missing numerical rows. Resulting dataset was partioned by airline identifier and saved as parquet file."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "00bde31c",
   "metadata": {},
   "source": [
    "## Exploratory Analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ca96ac72-af2a-4b7f-91d6-885113f51a60",
   "metadata": {},
   "source": [
    "To understand data better, we explored it by finding the most popular carriers:\n",
    "\n",
    "| UniqueCarrier | Count |\n",
    "|------|---------------|\n",
    "| WN | 1127045 | \n",
    "| AA | 548194 | \n",
    "| OO | 544843 | \n",
    "| MQ | 434577 | \n",
    "| DL | 424982 | \n",
    "| US | 411274 | \n",
    "| UA | 375501 | \n",
    "| XE | 308340 | \n",
    "| EV | 297874 | \n",
    "| NW | 291856 | \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "787234ca-688d-459c-8e5e-3602475a4f62",
   "metadata": {},
   "source": [
    "We also found the most important reasons for flight cancellation by respective codes:\n",
    "\n",
    "| CancellationCode | Count |\n",
    "|------|---------------|\n",
    "| B | 36651 | \n",
    "| A | 35568 | \n",
    "| C | 14799 | \n",
    "| D | 20 | \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8331fded-402f-4923-ab13-54d56a590fa2",
   "metadata": {},
   "source": [
    "Finally, we analysed the flight status imbalance ratio: \n",
    "\n",
    "| CANCELLED | Count |\n",
    "|------|---------------|\n",
    "| 0.0 | 6326977 | \n",
    "| 1.0 | 87038 | \n",
    " \n",
    "There are about 72 times more normally operating than cancelled flights."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "849c8cb9",
   "metadata": {},
   "source": [
    "## Feature Engineering"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6d5ea838-5ed9-4dff-b876-4da4aa57f7ef",
   "metadata": {},
   "source": [
    "We identified features, that are leaking information for flight cancellation, and would most likely not be available in prediction time. For that, we compared each feature min, max and mean values for both outcomes(cancelled or not). We dropped features, that had mostly zero values in one group only. I.e. Airtime values exist only for non-cancelled flights. Flight numbers were also removed as we were unsure if they consist any useful encoding, or are assigned randomly and can only introduce more noise. Additionally, we extracted expected arrival and departure hours in cyclical format.\n",
    "\n",
    "We converted all categorical variables with StringIndexer to numeric and used OneHotEncoder, to convert them into sparse binary vectors. Then, all features were assembled together with VectorAccembler and original, unconverted features were dropped from dataset.\n",
    "\n",
    "Dataset was split into train-test sets(0.7-0.3) while making sure that both sets have similar stratification ratio of target (cancellation) variable. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b71c6ac6",
   "metadata": {},
   "source": [
    "## Modeling\n",
    "\n",
    "We trained 4 different models as required by the task: LogisticRegression, DecisionTree, RandomForest and GBT. Due to computational complexity and time constraints, we ran CrossValidation for each of the models for just a single hyperparameter, testing 3 different values.\n",
    "\n",
    "All of the models had very similar accuracy but differing AUC scores. As the GBT model had the highest AUC, we chose that one as our model of choice.\n",
    "\n",
    "The GBT model does have a big downside of being more computationally expensive, since it relies on sequential operations for training. This meant that we could only do a very limited hyperparameter search in a reasonable amount of runtime. Thankfully inference is still very fast."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3d8bc818",
   "metadata": {},
   "source": [
    "## Explainability\n",
    "\n",
    "### Top 10 Features by Importance\n",
    "\n",
    "| Rank | Feature Index | Decoded Feature            | Importance Score | Interpretation |\n",
    "|------|---------------|----------------------------|------------------|----------------|\n",
    "| 1    | -             | **DepDelay**               | 0.5778           | Departure delay |\n",
    "| 2    | 633           | Month_9 (September)        | 0.0454           | Peak hurricane season |\n",
    "| 3    | 625           | Month_1 (January)          | 0.0357           | Winter storms |\n",
    "| 4    | 628           | Month_4 (April)            | 0.0311           | Spring break travel disruptions |\n",
    "| 5    | 632           | Month_8 (August)           | 0.0284           | Summer travel peaks |\n",
    "| 6    | 607           | UniqueCarrier_FL (AirTran) | 0.0259           | Out-of-business carrier |\n",
    "| 7    | -             | **Distance**               | 0.0253           | Longer flight risk |\n",
    "| 8    | 317           | Dest_ALO (Waterloo, IA)    | 0.0249           | Small Airport, Unpredictable Midwest weather |\n",
    "| 9    | 26            | Origin_ATW (Appleton, WI)  | 0.0244           | Small Airport, Unpredicatable Midwest Weather |\n",
    "| 10   | 304           | Dest_ABI (Abilene, TX)     | 0.0242           | Small Airport, Extreme Texas Weather |"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6357c0a2",
   "metadata": {},
   "source": [
    "## Model Persistence and Inference\n",
    "\n",
    "SparkML makes combining different processing steps very easy, as everything is basically a transformer. We also made a Preprocessor class that has a `_transform(self, df)` method, allowing it to be used as a pipeline stage. This means the we can combine everything into one big pipeline such that the raw dataframe goes in on one end and predictions come out the other.\n",
    "\n",
    "Testing this full pipeline on the 2010.csv dataset we achieved an accuracy score of <b>0.9824</b> and an AUC score of <b>0.9555</b>."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
